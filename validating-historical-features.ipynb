{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b3e96b",
   "metadata": {},
   "source": [
    "# Validating Historical Features with Great Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ff5f8",
   "metadata": {},
   "source": [
    "![Validating Historical Features with Great Expectations](./dqm-diagram-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98678d3b",
   "metadata": {},
   "source": [
    "In this tutorial, we will use the public dataset of Chicago taxi trips to present data validation capabilities of Feast. The original dataset is stored in BigQuery and consists of raw data for each taxi trip (one row per trip) since 2013. We will generate several training datasets (aka historical features in Feast) for different periods and evaluate expectations made on one dataset against another. Our features will represent aggregations of raw data with daily intervals (eg, trips per day, average fare or speed for a specific day, etc.). We will craft some features using SQL while pulling data from BigQuery (like total trips time or total miles travelled). Another chunk of features will be implemented using Feast's on-demand transformations - features calculated on the fly when requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a81e7",
   "metadata": {},
   "source": [
    "Our plan:\n",
    "\n",
    "0. Prepare environment\n",
    "1. Pull data from BigQuery (optional)\n",
    "2. Declare & apply features and feature views in Feast\n",
    "3. Generate reference dataset\n",
    "4. Develop & test profiler function\n",
    "5. Run validation on different dataset using reference dataset & profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66b943",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30caf020",
   "metadata": {},
   "source": [
    "Install Feast Python SDK and great expectations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'feast[ge]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbebd8",
   "metadata": {},
   "source": [
    "### 1. Dataset preparation (Optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875bb35",
   "metadata": {},
   "source": [
    "**You can skip this step if you don't have GCP account. Please use parquet files that are coming with this tutorial instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet\n",
    "\n",
    "from google.cloud.bigquery import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = Client(project='kf-feast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db5709",
   "metadata": {},
   "source": [
    "Running some basic aggregations while pulling data from BigQuery. Grouping by taxi_id and day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_query = \"\"\"SELECT \n",
    "    taxi_id,\n",
    "    TIMESTAMP_TRUNC(trip_start_timestamp, DAY) as day,\n",
    "    SUM(trip_miles) as total_miles_travelled,\n",
    "    SUM(trip_seconds) as total_trip_seconds,\n",
    "    SUM(fare) as total_earned,\n",
    "    COUNT(*) as trip_count\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` \n",
    "WHERE \n",
    "    trip_miles > 0 AND trip_seconds > 60 AND\n",
    "    trip_start_timestamp BETWEEN '2019-01-01' and '2020-12-31' AND\n",
    "    trip_total < 1000\n",
    "GROUP BY taxi_id, TIMESTAMP_TRUNC(trip_start_timestamp, DAY)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_stats_table = bq_client.query(data_query).to_arrow()\n",
    "\n",
    "# Storing resulting dataset into parquet file\n",
    "pyarrow.parquet.write_table(driver_stats_table, \"trips_stats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_query(year):\n",
    "    return f\"\"\"SELECT\n",
    "    distinct taxi_id\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` \n",
    "WHERE\n",
    "    trip_miles > 0 AND trip_seconds > 0 AND\n",
    "    trip_start_timestamp BETWEEN '{year}-01-01' and '{year}-12-31'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_2019_table = bq_client.query(entities_query(2019)).to_arrow()\n",
    "\n",
    "# Storing entities (taxi ids) into parquet file\n",
    "pyarrow.parquet.write_table(entities_2019_table, \"entities.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644201fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entities_2020_table = bq_client.query(entities_query(2020)).to_arrow()\n",
    "#pyarrow.parquet.write_table(entities_2019_table, \"entities_2020.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d40e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5faba1",
   "metadata": {},
   "source": [
    "## 2. Declaring features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cd609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureView, Entity, FeatureStore, Field, BatchFeatureView\n",
    "from feast.types import Float64, Int64\n",
    "from feast.value_type import ValueType\n",
    "from feast.data_format import ParquetFormat\n",
    "from feast.on_demand_feature_view import on_demand_feature_view\n",
    "from feast.infra.offline_stores.file_source import FileSource\n",
    "from feast.infra.offline_stores.file import SavedDatasetFileStorage\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ff6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_source = FileSource(\n",
    "    timestamp_field=\"day\",\n",
    "    path=\"trips_stats.parquet\",  # using parquet file that we created on previous step\n",
    "    file_format=ParquetFormat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc59092",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_entity = Entity(name='taxi', join_keys=['taxi_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dc7fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lrangine/Documents/Src/feast/sdk/python/feast/batch_feature_view.py:72: RuntimeWarning: Batch feature views are experimental features in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trips_stats_fv = BatchFeatureView(\n",
    "    name='trip_stats',\n",
    "    entities=[taxi_entity],\n",
    "    schema=[\n",
    "        Field(name=\"total_miles_travelled\", dtype=Float64),\n",
    "        Field(name=\"total_trip_seconds\", dtype=Float64),\n",
    "        Field(name=\"total_earned\", dtype=Float64),\n",
    "        Field(name=\"trip_count\", dtype=Int64),\n",
    "\n",
    "    ],\n",
    "    ttl=timedelta(seconds=86400),\n",
    "    source=batch_source,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b1567",
   "metadata": {},
   "source": [
    "*Read more about feature views in [Feast docs](https://docs.feast.dev/getting-started/concepts/feature-view)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d706f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@on_demand_feature_view(\n",
    "    sources=[\n",
    "      trips_stats_fv,\n",
    "    ],\n",
    "    schema=[\n",
    "        Field(name=\"avg_fare\", dtype=Float64),\n",
    "        Field(name=\"avg_speed\", dtype=Float64),\n",
    "        Field(name=\"avg_trip_seconds\", dtype=Float64),\n",
    "        Field(name=\"earned_per_hour\", dtype=Float64),\n",
    "    ]\n",
    ")\n",
    "def on_demand_stats(inp: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = pd.DataFrame()\n",
    "    out[\"avg_fare\"] = inp[\"total_earned\"] / inp[\"trip_count\"]\n",
    "    out[\"avg_speed\"] = 3600 * inp[\"total_miles_travelled\"] / inp[\"total_trip_seconds\"]\n",
    "    out[\"avg_trip_seconds\"] = inp[\"total_trip_seconds\"] / inp[\"trip_count\"]\n",
    "    out[\"earned_per_hour\"] = 3600 * inp[\"total_earned\"] / inp[\"total_trip_seconds\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff9a2e",
   "metadata": {},
   "source": [
    "*Read more about on demand feature views [here](https://docs.feast.dev/reference/alpha-on-demand-feature-view)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0c72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FeatureStore(\".\")  # using feature_store.yaml that stored in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8935e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lrangine/Documents/Src/feast/sdk/python/feast/feature_store.py:534: RuntimeWarning: On demand feature view is an experimental feature. This API is stable, but the functionality does not scale well for offline retrieval\n",
      "  warnings.warn(\n",
      "/Users/lrangine/Documents/Src/feast/sdk/python/feast/batch_feature_view.py:72: RuntimeWarning: Batch feature views are experimental features in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "store.apply([taxi_entity, trips_stats_fv, on_demand_stats])  # writing to the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ffb7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45de2545",
   "metadata": {},
   "source": [
    "## 3. Generating training (reference) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ba0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ids = pyarrow.parquet.read_table(\"entities.parquet\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee72c332",
   "metadata": {},
   "source": [
    "Generating range of timestamps with daily frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a558e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.DataFrame()\n",
    "timestamps[\"event_timestamp\"] = pd.date_range(\"2019-06-01\", \"2019-07-01\", freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db6725",
   "metadata": {},
   "source": [
    "Cross merge (aka relation multiplication) produces entity dataframe with each taxi_id repeated for each timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6ca83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2019-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2019-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2019-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2019-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2019-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156979</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156980</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156981</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156982</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2019-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156983</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156984 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  taxi_id event_timestamp\n",
       "0       91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2019-06-01\n",
       "1       91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2019-06-02\n",
       "2       91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2019-06-03\n",
       "3       91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2019-06-04\n",
       "4       91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2019-06-05\n",
       "...                                                   ...             ...\n",
       "156979  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2019-06-27\n",
       "156980  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2019-06-28\n",
       "156981  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2019-06-29\n",
       "156982  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2019-06-30\n",
       "156983  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2019-07-01\n",
       "\n",
       "[156984 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.merge(taxi_ids, timestamps, how='cross')\n",
    "entity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1263617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f39876",
   "metadata": {},
   "source": [
    "Retriving historical features for resulting entity dataframe and persisting output as a saved dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4af1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"trip_stats:total_miles_travelled\",\n",
    "        \"trip_stats:total_trip_seconds\",\n",
    "        \"trip_stats:total_earned\",\n",
    "        \"trip_stats:trip_count\",\n",
    "        \"on_demand_stats:avg_fare\",\n",
    "        \"on_demand_stats:avg_trip_seconds\",\n",
    "        \"on_demand_stats:avg_speed\",\n",
    "        \"on_demand_stats:earned_per_hour\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "store.create_saved_dataset(\n",
    "    from_=job,\n",
    "    name='my_training_ds',\n",
    "    storage=SavedDatasetFileStorage(path='my_training_ds.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a180b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439de503",
   "metadata": {},
   "source": [
    "## 4. Developing dataset profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b14d9",
   "metadata": {},
   "source": [
    "Dataset profiler is a function that accepts dataset and generates set of its characteristics. This charasteristics will be then used to evaluate (validate) next datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2c8b2",
   "metadata": {},
   "source": [
    "**Important: datasets are not compared to each other! \n",
    "Feast use a reference dataset and a profiler function to generate a reference profile. \n",
    "This profile will be then used during validation of the tested dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46f571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/feast-3.11/lib/python3.11/site-packages/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "/usr/local/anaconda3/envs/feast-3.11/lib/python3.11/site-packages/pyspark/sql/connect/utils.py:50: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(grpc.__version__) < LooseVersion(minimum_grpc_version):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from feast.dqm.profilers.ge_profiler import ge_profiler\n",
    "\n",
    "from great_expectations.core.expectation_suite import ExpectationSuite\n",
    "from great_expectations.dataset import PandasDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d157e99",
   "metadata": {},
   "source": [
    "Loading saved dataset first and exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57a229b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>earned_per_hour</th>\n",
       "      <th>total_earned</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>avg_fare</th>\n",
       "      <th>total_miles_travelled</th>\n",
       "      <th>avg_speed</th>\n",
       "      <th>avg_trip_seconds</th>\n",
       "      <th>total_trip_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d13c5aaa066f94b4927779ed24cd313b0c686f03407095...</td>\n",
       "      <td>2019-06-01 00:00:00+00:00</td>\n",
       "      <td>45.559701</td>\n",
       "      <td>203.50</td>\n",
       "      <td>8</td>\n",
       "      <td>25.437500</td>\n",
       "      <td>69.50</td>\n",
       "      <td>15.559701</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>16080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33164e16dd29b1c58cd15cce31df4bfcb75d9903cb66de...</td>\n",
       "      <td>2019-06-01 00:00:00+00:00</td>\n",
       "      <td>36.219512</td>\n",
       "      <td>74.25</td>\n",
       "      <td>5</td>\n",
       "      <td>14.850000</td>\n",
       "      <td>15.80</td>\n",
       "      <td>7.707317</td>\n",
       "      <td>1476.000000</td>\n",
       "      <td>7380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226fe0b00be42932bdff81bc0b318b883bfbf15dd48093...</td>\n",
       "      <td>2019-06-01 00:00:00+00:00</td>\n",
       "      <td>54.212598</td>\n",
       "      <td>114.75</td>\n",
       "      <td>6</td>\n",
       "      <td>19.125000</td>\n",
       "      <td>38.50</td>\n",
       "      <td>18.188976</td>\n",
       "      <td>1270.000000</td>\n",
       "      <td>7620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a5bed1b5ced617d0594007d591f10bbbca354d50b19ca...</td>\n",
       "      <td>2019-06-01 00:00:00+00:00</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>70.75</td>\n",
       "      <td>4</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>20.22</td>\n",
       "      <td>12.860777</td>\n",
       "      <td>1415.000000</td>\n",
       "      <td>5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7f7dbb452c0fb980a0f2050a146147c1006fe5f34e3b0...</td>\n",
       "      <td>2019-06-01 00:00:00+00:00</td>\n",
       "      <td>53.783319</td>\n",
       "      <td>104.25</td>\n",
       "      <td>5</td>\n",
       "      <td>20.850000</td>\n",
       "      <td>34.49</td>\n",
       "      <td>17.793637</td>\n",
       "      <td>1395.600000</td>\n",
       "      <td>6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119803</th>\n",
       "      <td>961263722c1beadafef2355412d672acac35e4054f6aaa...</td>\n",
       "      <td>2019-07-01 00:00:00+00:00</td>\n",
       "      <td>76.369295</td>\n",
       "      <td>102.25</td>\n",
       "      <td>4</td>\n",
       "      <td>25.562500</td>\n",
       "      <td>36.98</td>\n",
       "      <td>27.619917</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119804</th>\n",
       "      <td>8b07f9156e568a37d362463c84dbd1118b4eeb753bae50...</td>\n",
       "      <td>2019-07-01 00:00:00+00:00</td>\n",
       "      <td>52.677165</td>\n",
       "      <td>111.50</td>\n",
       "      <td>11</td>\n",
       "      <td>10.136364</td>\n",
       "      <td>29.00</td>\n",
       "      <td>13.700787</td>\n",
       "      <td>692.727273</td>\n",
       "      <td>7620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119805</th>\n",
       "      <td>a112879f10892d5c698ce150af17aa28615b6d005ca749...</td>\n",
       "      <td>2019-07-01 00:00:00+00:00</td>\n",
       "      <td>54.649682</td>\n",
       "      <td>143.00</td>\n",
       "      <td>16</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>31.00</td>\n",
       "      <td>11.847134</td>\n",
       "      <td>588.750000</td>\n",
       "      <td>9420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119806</th>\n",
       "      <td>68fe14b9fc2d53de5ac349d47f80f43fea895e201a31e3...</td>\n",
       "      <td>2019-07-01 00:00:00+00:00</td>\n",
       "      <td>73.770492</td>\n",
       "      <td>101.25</td>\n",
       "      <td>3</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>37.86</td>\n",
       "      <td>27.584699</td>\n",
       "      <td>1647.000000</td>\n",
       "      <td>4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119807</th>\n",
       "      <td>6933327f9cc740e893a882282f7d06460207d6d4e084b3...</td>\n",
       "      <td>2019-07-01 00:00:00+00:00</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>218.25</td>\n",
       "      <td>21</td>\n",
       "      <td>10.392857</td>\n",
       "      <td>58.90</td>\n",
       "      <td>18.216495</td>\n",
       "      <td>554.285714</td>\n",
       "      <td>11640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119808 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  taxi_id  \\\n",
       "0       d13c5aaa066f94b4927779ed24cd313b0c686f03407095...   \n",
       "1       33164e16dd29b1c58cd15cce31df4bfcb75d9903cb66de...   \n",
       "2       226fe0b00be42932bdff81bc0b318b883bfbf15dd48093...   \n",
       "3       5a5bed1b5ced617d0594007d591f10bbbca354d50b19ca...   \n",
       "4       b7f7dbb452c0fb980a0f2050a146147c1006fe5f34e3b0...   \n",
       "...                                                   ...   \n",
       "119803  961263722c1beadafef2355412d672acac35e4054f6aaa...   \n",
       "119804  8b07f9156e568a37d362463c84dbd1118b4eeb753bae50...   \n",
       "119805  a112879f10892d5c698ce150af17aa28615b6d005ca749...   \n",
       "119806  68fe14b9fc2d53de5ac349d47f80f43fea895e201a31e3...   \n",
       "119807  6933327f9cc740e893a882282f7d06460207d6d4e084b3...   \n",
       "\n",
       "                 event_timestamp  earned_per_hour  total_earned  trip_count  \\\n",
       "0      2019-06-01 00:00:00+00:00        45.559701        203.50           8   \n",
       "1      2019-06-01 00:00:00+00:00        36.219512         74.25           5   \n",
       "2      2019-06-01 00:00:00+00:00        54.212598        114.75           6   \n",
       "3      2019-06-01 00:00:00+00:00        45.000000         70.75           4   \n",
       "4      2019-06-01 00:00:00+00:00        53.783319        104.25           5   \n",
       "...                          ...              ...           ...         ...   \n",
       "119803 2019-07-01 00:00:00+00:00        76.369295        102.25           4   \n",
       "119804 2019-07-01 00:00:00+00:00        52.677165        111.50          11   \n",
       "119805 2019-07-01 00:00:00+00:00        54.649682        143.00          16   \n",
       "119806 2019-07-01 00:00:00+00:00        73.770492        101.25           3   \n",
       "119807 2019-07-01 00:00:00+00:00        67.500000        218.25          21   \n",
       "\n",
       "         avg_fare  total_miles_travelled  avg_speed  avg_trip_seconds  \\\n",
       "0       25.437500                  69.50  15.559701       2010.000000   \n",
       "1       14.850000                  15.80   7.707317       1476.000000   \n",
       "2       19.125000                  38.50  18.188976       1270.000000   \n",
       "3       17.687500                  20.22  12.860777       1415.000000   \n",
       "4       20.850000                  34.49  17.793637       1395.600000   \n",
       "...           ...                    ...        ...               ...   \n",
       "119803  25.562500                  36.98  27.619917       1205.000000   \n",
       "119804  10.136364                  29.00  13.700787        692.727273   \n",
       "119805   8.937500                  31.00  11.847134        588.750000   \n",
       "119806  33.750000                  37.86  27.584699       1647.000000   \n",
       "119807  10.392857                  58.90  18.216495        554.285714   \n",
       "\n",
       "        total_trip_seconds  \n",
       "0                    16080  \n",
       "1                     7380  \n",
       "2                     7620  \n",
       "3                     5660  \n",
       "4                     6978  \n",
       "...                    ...  \n",
       "119803                4820  \n",
       "119804                7620  \n",
       "119805                9420  \n",
       "119806                4941  \n",
       "119807               11640  \n",
       "\n",
       "[119808 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = store.get_saved_dataset('my_training_ds')\n",
    "ds.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73feb39d",
   "metadata": {},
   "source": [
    "Feast uses [Great Expectations](https://docs.greatexpectations.io/docs/) as a validation engine and [ExpectationSuite](https://legacy.docs.greatexpectations.io/en/latest/autoapi/great_expectations/core/expectation_suite/index.html#great_expectations.core.expectation_suite.ExpectationSuite) as a dataset's profile. Hence, we need to develop a function that will generate ExpectationSuite. This function will receive instance of [PandasDataset](https://legacy.docs.greatexpectations.io/en/latest/autoapi/great_expectations/dataset/index.html?highlight=pandasdataset#great_expectations.dataset.PandasDataset) (wrapper around pandas.DataFrame) so we can utilize both Pandas DataFrame API and some helper functions from PandasDataset during profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a8714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 0.1  # controlling allowed window in fraction of the value on scale [0, 1]\n",
    "\n",
    "@ge_profiler\n",
    "def stats_profiler(ds: PandasDataset) -> ExpectationSuite:\n",
    "    # simple checks on data consistency\n",
    "    ds.expect_column_values_to_be_between(\n",
    "        \"avg_speed\",\n",
    "        min_value=0,\n",
    "        max_value=60,\n",
    "        mostly=0.99  # allow some outliers\n",
    "    )\n",
    "\n",
    "    ds.expect_column_values_to_be_between(\n",
    "        \"total_miles_travelled\",\n",
    "        min_value=0,\n",
    "        max_value=500,\n",
    "        mostly=0.99  # allow some outliers\n",
    "    )\n",
    "\n",
    "    # expectation of means based on observed values\n",
    "    observed_mean = ds.trip_count.mean()\n",
    "    ds.expect_column_mean_to_be_between(\"trip_count\",\n",
    "                                        min_value=observed_mean * (1 - DELTA),\n",
    "                                        max_value=observed_mean * (1 + DELTA))\n",
    "\n",
    "    observed_mean = ds.earned_per_hour.mean()\n",
    "    ds.expect_column_mean_to_be_between(\"earned_per_hour\",\n",
    "                                        min_value=observed_mean * (1 - DELTA),\n",
    "                                        max_value=observed_mean * (1 + DELTA))\n",
    "\n",
    "\n",
    "    # expectation of quantiles\n",
    "    qs = [0.5, 0.75, 0.9, 0.95]\n",
    "    observed_quantiles = ds.avg_fare.quantile(qs)\n",
    "\n",
    "    ds.expect_column_quantile_values_to_be_between(\n",
    "        \"avg_fare\",\n",
    "        quantile_ranges={\n",
    "            \"quantiles\": qs,\n",
    "            \"value_ranges\": [[None, max_value] for max_value in observed_quantiles]\n",
    "        })\n",
    "\n",
    "    return ds.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f2e171",
   "metadata": {},
   "source": [
    "Testing our profiler function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504e5699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GEProfile with expectations: [\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_speed\",\n",
       "      \"min_value\": 0,\n",
       "      \"max_value\": 60,\n",
       "      \"mostly\": 0.99\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"total_miles_travelled\",\n",
       "      \"min_value\": 0,\n",
       "      \"max_value\": 500,\n",
       "      \"mostly\": 0.99\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"trip_count\",\n",
       "      \"min_value\": 10.387244591346153,\n",
       "      \"max_value\": 12.695521167200855\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"earned_per_hour\",\n",
       "      \"min_value\": 52.32062497564023,\n",
       "      \"max_value\": 63.9474305257825\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_quantile_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_fare\",\n",
       "      \"quantile_ranges\": {\n",
       "        \"quantiles\": [\n",
       "          0.5,\n",
       "          0.75,\n",
       "          0.9,\n",
       "          0.95\n",
       "        ],\n",
       "        \"value_ranges\": [\n",
       "          [\n",
       "            null,\n",
       "            16.4\n",
       "          ],\n",
       "          [\n",
       "            null,\n",
       "            26.229166666666668\n",
       "          ],\n",
       "          [\n",
       "            null,\n",
       "            36.4375\n",
       "          ],\n",
       "          [\n",
       "            null,\n",
       "            42.0\n",
       "          ]\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  }\n",
       "]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_profile(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb184b9",
   "metadata": {},
   "source": [
    "**Verify that all expectations that we coded in our profiler are present here. Otherwise (if you can't find some expectations) it means that it failed to pass on the reference dataset (do it silently is default behavior of Great Expectations).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32709fff",
   "metadata": {},
   "source": [
    "Now we can create validation reference from dataset and profiler function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc27606",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_reference = ds.as_reference(name=\"validation_reference_dataset\", profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a9300",
   "metadata": {},
   "source": [
    "and test it against our existing retrieval job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba72e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = job.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0604b9f",
   "metadata": {},
   "source": [
    "Validation successfully passed as no exception were raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7540989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b6d4338",
   "metadata": {},
   "source": [
    "### 5. Validating new historical retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b16c93",
   "metadata": {},
   "source": [
    "Creating new timestamps for Dec 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25450aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast.dqm.errors import ValidationFailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f6e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.DataFrame()\n",
    "timestamps[\"event_timestamp\"] = pd.date_range(\"2020-12-01\", \"2020-12-07\", freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a5d3b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2020-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2020-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2020-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...</td>\n",
       "      <td>2020-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35443</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2020-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35444</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2020-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35445</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2020-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35446</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2020-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35447</th>\n",
       "      <td>7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...</td>\n",
       "      <td>2020-12-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 taxi_id event_timestamp\n",
       "0      91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2020-12-01\n",
       "1      91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2020-12-02\n",
       "2      91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2020-12-03\n",
       "3      91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2020-12-04\n",
       "4      91d5288487e87c5917b813ba6f75ab1c3a9749af906a2d...      2020-12-05\n",
       "...                                                  ...             ...\n",
       "35443  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2020-12-03\n",
       "35444  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2020-12-04\n",
       "35445  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2020-12-05\n",
       "35446  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2020-12-06\n",
       "35447  7ebf27414a0c7b128e7925e1da56d51a8b81484f7630cf...      2020-12-07\n",
       "\n",
       "[35448 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.merge(taxi_ids, timestamps, how='cross')\n",
    "entity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be40a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"trip_stats:total_miles_travelled\",\n",
    "        \"trip_stats:total_trip_seconds\",\n",
    "        \"trip_stats:total_earned\",\n",
    "        \"trip_stats:trip_count\",\n",
    "        \"on_demand_stats:avg_fare\",\n",
    "        \"on_demand_stats:avg_trip_seconds\",\n",
    "        \"on_demand_stats:avg_speed\",\n",
    "        \"on_demand_stats:earned_per_hour\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12295b",
   "metadata": {},
   "source": [
    "Execute retrieval job with validation reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3279f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"success\": false,\n",
      "    \"expectation_config\": {\n",
      "      \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"trip_count\",\n",
      "        \"min_value\": 10.387244591346153,\n",
      "        \"max_value\": 12.695521167200855,\n",
      "        \"result_format\": \"COMPLETE\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"observed_value\": 6.692920555429092,\n",
      "      \"element_count\": 4393,\n",
      "      \"missing_count\": null,\n",
      "      \"missing_percent\": null\n",
      "    },\n",
      "    \"meta\": {},\n",
      "    \"exception_info\": {\n",
      "      \"raised_exception\": false,\n",
      "      \"exception_message\": null,\n",
      "      \"exception_traceback\": null\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"success\": false,\n",
      "    \"expectation_config\": {\n",
      "      \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"earned_per_hour\",\n",
      "        \"min_value\": 52.32062497564023,\n",
      "        \"max_value\": 63.9474305257825,\n",
      "        \"result_format\": \"COMPLETE\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"observed_value\": 68.99268345164135,\n",
      "      \"element_count\": 4393,\n",
      "      \"missing_count\": null,\n",
      "      \"missing_percent\": null\n",
      "    },\n",
      "    \"meta\": {},\n",
      "    \"exception_info\": {\n",
      "      \"raised_exception\": false,\n",
      "      \"exception_message\": null,\n",
      "      \"exception_traceback\": null\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"success\": false,\n",
      "    \"expectation_config\": {\n",
      "      \"expectation_type\": \"expect_column_quantile_values_to_be_between\",\n",
      "      \"kwargs\": {\n",
      "        \"column\": \"avg_fare\",\n",
      "        \"quantile_ranges\": {\n",
      "          \"quantiles\": [\n",
      "            0.5,\n",
      "            0.75,\n",
      "            0.9,\n",
      "            0.95\n",
      "          ],\n",
      "          \"value_ranges\": [\n",
      "            [\n",
      "              null,\n",
      "              16.4\n",
      "            ],\n",
      "            [\n",
      "              null,\n",
      "              26.229166666666668\n",
      "            ],\n",
      "            [\n",
      "              null,\n",
      "              36.4375\n",
      "            ],\n",
      "            [\n",
      "              null,\n",
      "              42.0\n",
      "            ]\n",
      "          ]\n",
      "        },\n",
      "        \"result_format\": \"COMPLETE\"\n",
      "      },\n",
      "      \"meta\": {}\n",
      "    },\n",
      "    \"result\": {\n",
      "      \"observed_value\": {\n",
      "        \"quantiles\": [\n",
      "          0.5,\n",
      "          0.75,\n",
      "          0.9,\n",
      "          0.95\n",
      "        ],\n",
      "        \"values\": [\n",
      "          19.5,\n",
      "          28.1,\n",
      "          38.0,\n",
      "          44.125\n",
      "        ]\n",
      "      },\n",
      "      \"element_count\": 4393,\n",
      "      \"missing_count\": null,\n",
      "      \"missing_percent\": null,\n",
      "      \"details\": {\n",
      "        \"success_details\": [\n",
      "          false,\n",
      "          false,\n",
      "          false,\n",
      "          false\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"meta\": {},\n",
      "    \"exception_info\": {\n",
      "      \"raised_exception\": false,\n",
      "      \"exception_message\": null,\n",
      "      \"exception_traceback\": null\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = job.to_df(validation_reference=validation_reference)\n",
    "except ValidationFailed as exc:\n",
    "    print(exc.validation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f1935",
   "metadata": {},
   "source": [
    "Validation failed since several expectations didn't pass:\n",
    "* Trip count (mean) decreased more than 10% (which is expected when comparing Dec 2020 vs June 2019)\n",
    "* Average Fare increased - all quantiles are higher than expected\n",
    "* Earn per hour (mean) increased more than 10% (most probably due to increased fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d59c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
